{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c314042d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import requests\n",
    "from os import path\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aad47d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read file method\n",
    "def read_file(filename):\n",
    "    with open(filename) as f:\n",
    "        content = f.readlines()\n",
    "    return [x.strip() for x in content]\n",
    "\n",
    "# Method to check if file exists or not\n",
    "def checkfile(filename):\n",
    "    return path.exists(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35bff518",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the path to the direcory where your 4 parameter files mentioned in the next cell are present.\n",
    "parameter_path = 'parameter'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf676f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass the file names for the respective things, please don't change these names if possible, if you are changing, please be careful\n",
    "hyperlink_file = \"hyperlink.txt\"\n",
    "filenames_file = \"savefiles.txt\"\n",
    "baselink_file = \"base.txt\"\n",
    "parameter_file = \"parameters.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a64d0ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the years as per your requirement\n",
    "years = [\"2014-2015\", \"2015-2016\", \"2016-2017\", \"2017-2018\", \"2018-2019\",\"2019-2020\", \"2020-2021\"]\n",
    "\n",
    "# reading all the files for specifications and getting the content into lists\n",
    "hyperlink_lines = read_file(path.join(parameter_path, hyperlink_file))\n",
    "parameter_lines = read_file(path.join(parameter_path, parameter_file))\n",
    "savedhtml_lines = read_file(path.join(parameter_path, filenames_file))\n",
    "basehtml_lines = read_file(path.join(parameter_path, baselink_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c879daee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(hyperlink_lines)):\n",
    "    # Getting the url\n",
    "    url = hyperlink_lines[i]\n",
    "\n",
    "    # Getting the parameter name\n",
    "    param = savedhtml_lines[i]\n",
    "\n",
    "    # Creating the directory for the parameter, if doesn't exist\n",
    "    param_dir = path.join(\"html\", param)\n",
    "    if not path.join(param_dir):\n",
    "        os.makedirs(param_dir)\n",
    "\n",
    "    # Iterating through the years\n",
    "    for year in years:\n",
    "\n",
    "        # Creating the directory for the yeawr, if doesn't exist\n",
    "        year_dir = path.join(param_dir, year)\n",
    "        if not path.exists(year_dir):\n",
    "            os.makedirs(year_dir)\n",
    "\n",
    "        # Appending the year parameter to the url\n",
    "        year_url = url + year\n",
    "        print(f'year url: {year_url}')\n",
    "        soup = BeautifulSoup(requests.get(year_url).content,'html.parser')\n",
    "\n",
    "        # Getting all the states into the table on the webpage\n",
    "        states = soup.findAll(\"tr\")[5:-1]\n",
    "\n",
    "        # Iterating through each of the state\n",
    "        for state in states:\n",
    "            try:\n",
    "                # State name with link in the 2nd column, so moving to the next sibling\n",
    "                state_element = state.find('td').find_next_sibling(\"td\")\n",
    "\n",
    "                # Getting the href link from the element\n",
    "                href_element = state_element.find_all(href = True)\n",
    "\n",
    "                # Check if there exist an href link\n",
    "                if len(href_element) != 0:\n",
    "                    # Append the link to the base html url\n",
    "                    html_link = basehtml_lines[i] + href_element[0]['href']\n",
    "\n",
    "                    state_name = href_element[0].text\n",
    "                    print(f'State: {state_name}')\n",
    "\n",
    "                    # Check if the state name is non-empty\n",
    "                    if state_name == \"\":\n",
    "                        print(f\"State not available\")\n",
    "                        continue\n",
    "\n",
    "                    # Creating the directory for the state if doesn't exist\n",
    "                    state_dir = path.join(year_dir, state_name)\n",
    "                    if not path.exists(state_dir):\n",
    "                        os.makedirs(state_dir)\n",
    "\n",
    "                    # Getting the districts using the link for the state formed above\n",
    "                    dsoup = BeautifulSoup(requests.get(html_link).content,'html.parser')\n",
    "                    districts = dsoup.findAll(\"tr\")[5:-1]\n",
    "\n",
    "                    # Iterating over each of the district\n",
    "                    for district in districts:\n",
    "                        try:\n",
    "\n",
    "                            # Getting the district link element from the 2nd column\n",
    "                            district_element = district.find('td').find_next_sibling(\"td\")\n",
    "\n",
    "                            # Getting the href element from it\n",
    "                            href_element = district_element.find_all(href=True)\n",
    "\n",
    "                            # If there exist a link, go ahead\n",
    "                            if len(href_element) != 0:\n",
    "\n",
    "                                # Append the link to the base url                       \n",
    "                                html_link = basehtml_lines[i] + href_element[0]['href']\n",
    "\n",
    "                                district_name = href_element[0].text\n",
    "\n",
    "                                # Check if the district name is non-empty\n",
    "                                if district_name == \"\":\n",
    "                                    print(f\"District in State: {state_name} not available\")\n",
    "\n",
    "                                # Create the district directory if doesn't exist\n",
    "                                district_dir = path.join(state_dir, district_name)\n",
    "                                if not path.exists(district_dir):\n",
    "                                    os.makedirs(district_dir)\n",
    "                    \n",
    "                                # Getting the blocks from the district page link formed above\n",
    "                                bsoup = BeautifulSoup(requests.get(html_link).content,'html.parser')\n",
    "                                blocks = bsoup.findAll(\"tr\")[5:-1]\n",
    "\n",
    "                                # Iterating through each of the block\n",
    "                                for block in blocks:\n",
    "                                    try:\n",
    "\n",
    "                                        # Getting the block name and link from the 2nd column\n",
    "                                        block_element = block.find('td').find_next_sibling(\"td\")\n",
    "                                        href_element = block_element.find_all(href=True)\n",
    "\n",
    "                                        # Check if there exists a link\n",
    "                                        if len(href_element) != 0:\n",
    "\n",
    "                                            # Append the href link obtained to the base url\n",
    "                                            html_link = basehtml_lines[i] + href_element[0]['href']\n",
    "                                            block_name = href_element[0].text\n",
    "\n",
    "                                            # Check if the block name is empty\n",
    "                                            if block_name == \"\":\n",
    "                                                print(f\"Block in District {district_name} not available\")\n",
    "                                            \n",
    "                                            # Check if the block file already exists\n",
    "                                            if path.exists(path.join(district_dir, block_name + \".html\")):\n",
    "                                                continue\n",
    "\n",
    "                                            # Getting the block page\n",
    "                                            block_page = requests.get(html_link).content\n",
    "\n",
    "                                            # Saving the block page to html file\n",
    "                                            file = open(os.path.join(district_dir, block_name + \".html\"), 'wb')\n",
    "                                            # Write the block page\n",
    "                                            file.write(block_page)\n",
    "                                            \n",
    "                                            print(\"html file saved\")\n",
    "                                            file.close()\n",
    "                                            \n",
    "                                    except Exception as e:\n",
    "                                        print(e)                      \n",
    "                        except Exception as e:\n",
    "                            print(e)\n",
    "        \n",
    "            except Exception as e:\n",
    "                print(e)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
